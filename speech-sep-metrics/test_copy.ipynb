{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Arian\\.conda\\envs\\inference\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "The torchaudio backend is switched to 'soundfile'. Note that 'sox_io' is not supported on Windows.\n",
      "The torchaudio backend is switched to 'soundfile'. Note that 'sox_io' is not supported on Windows.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torchaudio\n",
    "import speechbrain as sb\n",
    "import speechbrain.nnet.schedulers as schedulers\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import logging\n",
    "from hyperpyyaml import load_hyperpyyaml\n",
    "import csv\n",
    "device = torch.device('cuda')\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "# from mir_eval.separation import bss_eval_sources\n",
    "from speechbrain.dataio.dataio import read_audio\n",
    "from fast_bss_eval import bss_eval_sources"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_all_audio(path):\n",
    "   audio_ids = []\n",
    "   out_target = {}\n",
    "   out_est = {}\n",
    "   out_mix = []\n",
    "   for filename in os.listdir(path):\n",
    "      filepath = os.path.join(path, filename)\n",
    "      item_num = filename.split('_')[0]\n",
    "      audio = read_audio(filepath).unsqueeze(0).to(device)\n",
    "      if \"hat\" in filename:\n",
    "         if  item_num in out_est:\n",
    "            out_est[item_num].append(audio)\n",
    "         else: \n",
    "            out_est[item_num]  = [audio]\n",
    "      elif \"mix\" not in filename:\n",
    "         if  item_num in out_est:\n",
    "            out_target[item_num].append(audio)\n",
    "         else: \n",
    "            out_target[item_num]  = [audio]\n",
    "      elif \"mix\" in filename:\n",
    "         audio_ids.append(item_num.replace('item',''))\n",
    "         out_mix.append(audio)\n",
    "   out_target = list(out_target.values())\n",
    "   out_est = list(out_est.values())\n",
    "      \n",
    "   return audio_ids, out_target, out_est, out_mix\n",
    "\n",
    "audio_ids,out_target, out_est, out_mix = read_all_audio('results/audio_results')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Separation(sb.Brain):\n",
    "   def compute_objectives(self, predictions, targets):\n",
    "        \"\"\"Computes the si-snr loss\"\"\"\n",
    "        return self.hparams.loss(targets, predictions)\n",
    "     \n",
    "   def get_metrics(self,audio_ids, targets, preds, mixtures):\n",
    "\n",
    "        # Create folders where to store audio\n",
    "      save_file = os.path.join(self.hparams.output_folder, \"test_results.csv\")\n",
    "\n",
    "        # Variable init\n",
    "\n",
    "      all_sdrs = []\n",
    "      all_sdrs_i = []\n",
    "      all_sisnrs = []\n",
    "      all_sisnrs_i = []\n",
    "      csv_columns = [\"audio_id\", \"sdr\", \"sdr_i\", \"si-snr\", \"si-snr_i\"]\n",
    "\n",
    "        \n",
    "\n",
    "      with open(save_file, \"w\") as results_csv:\n",
    "         writer = csv.DictWriter(results_csv, fieldnames=csv_columns)\n",
    "         writer.writeheader()\n",
    "            \n",
    "         for audio_id, target, pred,mixture_ in tqdm(zip(audio_ids,targets, preds,mixtures), total=len(targets)):\n",
    "   \n",
    "            # Compute SI-SNR\n",
    "            target = torch.cat(\n",
    "            [target[i].unsqueeze(-1) for i in range(self.hparams.num_spks)],\n",
    "            dim=-1,\n",
    "        ).to(self.device)\n",
    "            \n",
    "            pred = torch.cat(\n",
    "            [pred[i].unsqueeze(-1) for i in range(self.hparams.num_spks)],\n",
    "            dim=-1,\n",
    "        ).to(self.device)\n",
    "  \n",
    "            sisnr = self.compute_objectives(pred, target)\n",
    "            # COmpute SI-SNR Improvement\n",
    "            mixture_signal = torch.stack(\n",
    "               [mixture_] * self.hparams.num_spks, dim=-1\n",
    "            )\n",
    "            mixture_signal = mixture_signal.to(target.device)\n",
    "            sisnr_baseline = self.compute_objectives(\n",
    "               mixture_signal, target\n",
    "            )\n",
    "            sisnr_i = sisnr - sisnr_baseline\n",
    "  # Compute SDR\n",
    "            sdr, _, _, _ = bss_eval_sources(\n",
    "               target[0].t(),\n",
    "               pred[0].t(),\n",
    "            )\n",
    "\n",
    "            sdr_baseline, _, _, _ = bss_eval_sources(\n",
    "               target[0].t(),\n",
    "               mixture_signal[0].t(),\n",
    "            )\n",
    "           \n",
    "            sdr_i = sdr.mean() - sdr_baseline.mean()\n",
    "\n",
    "            # Saving on a csv file\n",
    "            row = {\n",
    "               \"audio_id\": audio_id,\n",
    "               \"sdr\": sdr.mean().cpu().numpy(),\n",
    "               \"sdr_i\": sdr_i.cpu().numpy(),\n",
    "               \"si-snr\": -sisnr.item(),\n",
    "               \"si-snr_i\": -sisnr_i.item(),\n",
    "            }\n",
    "            writer.writerow(row)\n",
    "\n",
    "            # Metric Accumulation\n",
    "            all_sdrs.append(sdr.mean().cpu().numpy())\n",
    "            all_sdrs_i.append(sdr_i.mean().cpu().numpy())\n",
    "            all_sisnrs.append(-sisnr.item())\n",
    "            all_sisnrs_i.append(-sisnr_i.item())\n",
    "      logger.info(\"Mean SISNR is {}\".format(np.array(all_sisnrs).mean()))\n",
    "      logger.info(\"Mean SISNRi is {}\".format(np.array(all_sisnrs_i).mean()))\n",
    "      logger.info(\"Mean SDR is {}\".format(np.array(all_sdrs).mean()))\n",
    "      logger.info(\"Mean SDRi is {}\".format(np.array(all_sdrs_i).mean()))   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2604/2604 [02:18<00:00, 18.79it/s]\n"
     ]
    }
   ],
   "source": [
    "def run():\n",
    "    # Load hyperparameters file with command-line overrides\n",
    "   hparams_file, run_opts, overrides = sb.parse_arguments([\"hyperparams.yaml\"])\n",
    "   hparams_file = 'hyperparams.yaml'\n",
    "#    run_opts = {\"device\": \"cuda:0\"}\n",
    "   with open(hparams_file) as fin:\n",
    "      hparams = load_hyperpyyaml(fin, overrides)\n",
    "        \n",
    "      # Load pretrained model if pretrained_separator is present in the yaml\n",
    "   if \"pretrained_separator\" in hparams:\n",
    "       # run_on_main(hparams[\"pretrained_separator\"].collect_files)\n",
    "       hparams[\"pretrained_separator\"].load_collected(\n",
    "            device=run_opts[\"device\"]\n",
    "       )\n",
    "   # Brain class initialization\n",
    "   separator = Separation(\n",
    "        modules=hparams[\"modules\"],\n",
    "        run_opts={\"device\": \"cuda\"},\n",
    "        hparams=hparams,\n",
    "    )\n",
    "   separator.get_metrics(audio_ids, out_target, out_est, out_mix)\n",
    "run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "audio_id    2445.000000\n",
       "sdr           18.172338\n",
       "sdr_i         17.768276\n",
       "si-snr        17.021784\n",
       "si-snr_i      16.838556\n",
       "Name: 1445, dtype: float64"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df= pd.read_csv('results/test_results.csv')\n",
    "\n",
    "\n",
    "df.loc[df['sdr']== df['sdr'].median()]\n",
    "df.sort_values(by='sdr', inplace=True)\n",
    "# df[df['sdr'] > df['sdr'].median()].iloc[0]\n",
    "median_audio = df[df['sdr'] < df['sdr'].median()].iloc[-1]\n",
    "median_audio\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[df['sdr']== df['sdr'].median()]\n",
    "df.sort_values(by='sdr', inplace=True)\n",
    "# df[df['sdr'] > df['sdr'].median()].iloc[0]\n",
    "median_audio = df[df['sdr'] < df['sdr'].median()].iloc[-1]\n",
    "med"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "inference",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
