{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Arian\\.conda\\envs\\inference\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "The torchaudio backend is switched to 'soundfile'. Note that 'sox_io' is not supported on Windows.\n",
      "The torchaudio backend is switched to 'soundfile'. Note that 'sox_io' is not supported on Windows.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torchaudio\n",
    "import speechbrain as sb\n",
    "import speechbrain.nnet.schedulers as schedulers\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import logging\n",
    "from hyperpyyaml import load_hyperpyyaml\n",
    "import csv\n",
    "device = torch.device('cuda')\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "# from mir_eval.separation import bss_eval_sources\n",
    "from speechbrain.dataio.dataio import read_audio\n",
    "from fast_bss_eval import bss_eval_sources\n",
    "import librosa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import concurrent.futures\n",
    "def parse_audio(path):\n",
    "   audio,sr = torchaudio.load(path)\n",
    "   audio = torchaudio.functional.resample(audio, sr, 8000)\n",
    "   # audio, sr = librosa.load(path,sr=8000)\n",
    "   # audio = torch.from_numpy(audio).unsqueeze(0)\n",
    "   \n",
    "\n",
    "\n",
    "   # audio = audio\n",
    "   # print(audio.shape)\n",
    "   \n",
    "   return audio\n",
    "def append_audio(item_name, path, out_est, out_target, out_est_up, out_mix):\n",
    "   source1_path = f\"{path}/{item_name}_source1hat_up.wav\"\n",
    "   source2_path = f\"{path}/{item_name}_source2hat_up.wav\"\n",
    "   if not os.path.isfile(source1_path) or not os.path.isfile(source2_path):\n",
    "      return\n",
    "\n",
    "   # Orig\n",
    "   source1_path = f\"{path}/{item_name}_source1.wav\"\n",
    "   source2_path = f\"{path}/{item_name}_source2.wav\"\n",
    "   out_target[item_name] = [parse_audio(source1_path), parse_audio(source2_path)]\n",
    "\n",
    "   source1_path = f\"{path}/{item_name}_source1hat.wav\"\n",
    "   source2_path = f\"{path}/{item_name}_source2hat.wav\"\n",
    "   out_est[item_name] = [parse_audio(source1_path), parse_audio(source2_path)]\n",
    "   \n",
    "   source1_path = f\"{path}/{item_name}_source1hat_up.wav\"\n",
    "   source2_path = f\"{path}/{item_name}_source2hat_up.wav\"\n",
    "   out_est_up[item_name] = [parse_audio(source1_path), parse_audio(source2_path)]\n",
    "\n",
    "   mix_path = f\"{path}/{item_name}_mix.wav\"\n",
    "   out_mix[item_name]=(parse_audio(mix_path))\n",
    "\n",
    "def read_all_audio(path, upsampled=False):\n",
    "   \n",
    "   audio_ids = []\n",
    "   out_target= {}\n",
    "   out_est = {}\n",
    "   out_est_upsampled = {}\n",
    "   out_mix = {}\n",
    "   all_files = os.listdir(path)\n",
    "   item_names = [file_name.split('_')[0] for file_name in all_files] \n",
    "   item_names = list(set(item_names))\n",
    "   \n",
    "   # with concurrent.futures.ThreadPoolExecutor(max_workers=10) as executor:\n",
    "   for item_name in tqdm(item_names, total=len(item_names)):\n",
    "      append_audio(item_name, path, out_est, out_target, out_est_upsampled, out_mix)\n",
    "      \n",
    "   audio_ids =list(sorted(out_target.keys())) \n",
    "   out_target = list(dict(sorted(out_target.items())).values())\n",
    "   out_est= list(dict(sorted(out_est.items())).values())\n",
    "   out_est_upsampled= list(dict(sorted(out_est_upsampled.items())).values())\n",
    "   out_mix= list(dict(sorted(out_mix.items())).values())\n",
    "   return audio_ids, out_target, out_est,out_est_upsampled, out_mix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('ant', 'ayy'), ('dog', 'arf')]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = {\"dog\":\"arf\",\"ant\":\"ayy\"}\n",
    "sorted(test.items())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "class Separation(sb.Brain):\n",
    "   def compute_objectives(self, predictions, targets):\n",
    "        \"\"\"Computes the si-snr loss\"\"\"\n",
    "        return self.hparams.loss(targets, predictions)\n",
    "     \n",
    "   def get_metrics(self,audio_ids, targets, preds, mixtures,output_path):\n",
    "\n",
    "        # Create folders where to store audio\n",
    "      # save_file = os.path.join(output_path, \"test_results.csv\")\n",
    "      save_file = output_path\n",
    "\n",
    "        # Variable init\n",
    "\n",
    "      all_sdrs = []\n",
    "      all_sdrs_i = []\n",
    "      all_sisnrs = []\n",
    "      all_sisnrs_i = []\n",
    "      csv_columns = [\"snt_id\", \"sdr\", \"sdr_i\", \"si-snr\", \"si-snr_i\"]\n",
    "\n",
    "        \n",
    "      \n",
    "      with open(save_file, \"w\") as results_csv:\n",
    "         writer = csv.DictWriter(results_csv, fieldnames=csv_columns)\n",
    "         writer.writeheader()\n",
    "            \n",
    "         for audio_id, target, pred,mixture_ in tqdm(zip(audio_ids,targets, preds,mixtures), total=len(targets)):\n",
    "            target = torch.cat(\n",
    "            [target[i].unsqueeze(-1) for i in range(self.hparams.num_spks)],\n",
    "            dim=-1,\n",
    "        ).to(self.device)\n",
    "            \n",
    "            pred = torch.cat(\n",
    "            [pred[i].unsqueeze(-1) for i in range(self.hparams.num_spks)],\n",
    "            dim=-1,\n",
    "        ).to(self.device)\n",
    "            \n",
    "  \n",
    "            sisnr = self.compute_objectives(pred, target)\n",
    "            # COmpute SI-SNR Improvement\n",
    "            mixture_signal = torch.stack(\n",
    "               [mixture_] * self.hparams.num_spks, dim=-1\n",
    "            )\n",
    "            \n",
    "            arrs = [pred[0], target[0], mixture_signal[0]]\n",
    "            for item in arrs:\n",
    "               temp_item = (item!=np.inf).all() and (item!=np.NINF).all()\n",
    "               if not temp_item:\n",
    "                  continue\n",
    "            # if mixture_signal[0] == np.inf or mixture_signal[1] ==np.inf:\n",
    "            \n",
    "            mixture_signal = mixture_signal.to(target.device)\n",
    "            sisnr_baseline = self.compute_objectives(\n",
    "               mixture_signal, target\n",
    "            )\n",
    "            sisnr_i = sisnr.cpu().numpy() - sisnr_baseline.cpu().numpy()\n",
    "  # Compute SDR\n",
    "            sdr, _, _, _ = bss_eval_sources(\n",
    "               target[0].t(),\n",
    "               pred[0].t(),\n",
    "            )\n",
    "\n",
    "            sdr_baseline, _, _, _ = bss_eval_sources(\n",
    "               target[0].t(),\n",
    "               mixture_signal[0].t(),\n",
    "            )\n",
    "            \n",
    "            sdr = sdr.cpu().numpy()\n",
    "            sdr_baseline = sdr_baseline.cpu().numpy()\n",
    "           \n",
    "            sdr_i = sdr.mean() - sdr_baseline.mean()\n",
    "\n",
    "            # Saving on a csv file\n",
    "            row = {\n",
    "               \"snt_id\": audio_id,\n",
    "               \"sdr\": sdr.mean(),\n",
    "               \"sdr_i\": sdr_i,\n",
    "               \"si-snr\": -sisnr.item(),\n",
    "               \"si-snr_i\": -sisnr_i.item(),\n",
    "            }\n",
    "            writer.writerow(row)\n",
    "\n",
    "            # Metric Accumulation\n",
    "            all_sdrs.append(sdr.mean())\n",
    "            all_sdrs_i.append(sdr_i.mean())\n",
    "            all_sisnrs.append(-sisnr.item())\n",
    "            all_sisnrs_i.append(-sisnr_i.item())\n",
    "      # logger.info(\"Mean SISNR is {}\".format(np.array(all_sisnrs).mean()))\n",
    "      # logger.info(\"Mean SISNRi is {}\".format(np.array(all_sisnrs_i).mean()))\n",
    "      # logger.info(\"Mean SDR is {}\".format(np.array(all_sdrs).mean()))\n",
    "      # logger.info(\"Mean SDRi is {}\".format(np.array(all_sdrs_i).mean()))   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The torchaudio backend is switched to 'soundfile'. Note that 'sox_io' is not supported on Windows.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading epoch_30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2604/2604 [05:25<00:00,  8.00it/s]\n",
      "100%|██████████| 2176/2176 [04:21<00:00,  8.32it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done with epoch_30 | upsamle: False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2176/2176 [01:51<00:00, 19.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done with epoch_30 | upsamle: True\n",
      "Reading no_noise_speedperturb\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3000/3000 [06:21<00:00,  7.86it/s]\n",
      "100%|██████████| 3000/3000 [02:44<00:00, 18.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done with no_noise_speedperturb | upsamle: False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3000/3000 [02:43<00:00, 18.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done with no_noise_speedperturb | upsamle: True\n",
      "Reading w_noise_speedperturb\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3000/3000 [06:56<00:00,  7.20it/s]\n",
      "100%|██████████| 2999/2999 [02:48<00:00, 17.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done with w_noise_speedperturb | upsamle: False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2999/2999 [02:49<00:00, 17.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done with w_noise_speedperturb | upsamle: True\n",
      "Reading w_noise_wavedrop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3000/3000 [07:11<00:00,  6.95it/s]\n",
      "100%|██████████| 3000/3000 [02:53<00:00, 17.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done with w_noise_wavedrop | upsamle: False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3000/3000 [02:54<00:00, 17.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done with w_noise_wavedrop | upsamle: True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# # Load hyperparameters file with command-line overrides\n",
    "# hparams_file, run_opts, overrides = sb.parse_arguments([\"hyperparams.yaml\"])\n",
    "# hparams_file = 'hyperparams.yaml'\n",
    "# #    run_opts = {\"device\": \"cuda:0\"}\n",
    "# with open(hparams_file) as fin:\n",
    "#    hparams = load_hyperpyyaml(fin, overrides)\n",
    "   \n",
    "# # Load pretrained model if pretrained_separator is present in the yaml\n",
    "# if \"pretrained_separator\" in hparams:\n",
    "#    # run_on_main(hparams[\"pretrained_separator\"].collect_files)\n",
    "#    hparams[\"pretrained_separator\"].load_collected(\n",
    "#       device=run_opts[\"device\"]\n",
    "#    )\n",
    "# # Brain class initialization\n",
    "# separator = Separation(\n",
    "#    modules=hparams[\"modules\"],\n",
    "#    run_opts={\"device\": \"cuda\"},\n",
    "#    hparams=hparams,\n",
    "# )\n",
    "\n",
    "# configs = [\"epoch_30\",\"no_noise_speedperturb\",\"w_noise_speedperturb\",\"w_noise_wavedrop\"]\n",
    "# # configs = [\"w_noise_speedperturb\",\"w_noise_wavedrop\"]\n",
    "# # configs = [\"no_noise_speedperturb\"]\n",
    "# UPSAMPLE= [False,True]\n",
    "\n",
    "# for config in configs:\n",
    "#    print(f\"Reading {config}\")\n",
    "#    audio_ids,out_target, out_est, out_est_upsampled, out_mix = read_all_audio(f'results/{config}/audio_results')\n",
    "#    for is_upsample in UPSAMPLE:\n",
    "#       if is_upsample:\n",
    "#          out_est = out_est_upsampled   \n",
    "#       # upsample = \"upsampled\" if upsample else \"not_upsampled\"\n",
    "#       output_path = f\"results/{config}/{config}_{is_upsample}_test.csv\"\n",
    "#       separator.get_metrics(audio_ids, out_target, out_est, out_mix, output_path=output_path)\n",
    "#       print(f\"Done with {config} | upsamle: {is_upsample}\")\n",
    "# # output_path = f\"results/epoch_30/true_test_result.csv\"\n",
    "# # separator.get_metrics(audio_ids, out_target, out_est, out_mix, output_path=output_path)\n",
    "# # separator.get_metrics(audio_ids, out_est, out_est_upsampled, out_mix, output_path=output_path)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Retrieves the worst, median and best separation audio mixtures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------CONFIG: epoch_30 | upsampled: False\n",
      "status: Worst | sdr: -1.2749534 | sdr_i: -1.5892842 | si-snr: -2.5520501136779785 | si-snr_i: -2.5907351970672607\n",
      "status: Median | sdr: 18.149502 | sdr_i: 17.858213 | si-snr: 17.536113739013672 | si-snr_i: 17.619060516357422\n",
      "status: Best | sdr: 26.296406 | sdr_i: 26.069109 | si-snr: 26.019519805908203 | si-snr_i: 25.916349411010746\n",
      "mean_values sdr         17.684452\n",
      "sdr_i       17.503902\n",
      "si-snr      16.976102\n",
      "si-snr_i    16.975533\n",
      "dtype: float64\n",
      "------------CONFIG: epoch_30 | upsampled: True\n",
      "status: Worst | sdr: -1.268426 | sdr_i: -1.5827568 | si-snr: -2.594472885131836 | si-snr_i: -2.633157968521118\n",
      "status: Median | sdr: 17.894081 | sdr_i: 17.787064 | si-snr: 14.295371055603027 | si-snr_i: 14.396849632263184\n",
      "status: Best | sdr: 23.585714 | sdr_i: 23.513992 | si-snr: 20.99060440063477 | si-snr_i: 21.084444046020508\n",
      "mean_values sdr         15.873038\n",
      "sdr_i       15.692488\n",
      "si-snr      13.824626\n",
      "si-snr_i    13.824058\n",
      "dtype: float64\n",
      "------------CONFIG: no_noise_speedperturb | upsampled: False\n",
      "status: Worst | sdr: -1.7907553 | sdr_i: -3.983903 | si-snr: -5.504912376403809 | si-snr_i: -5.717061519622803\n",
      "status: Median | sdr: 8.186708 | sdr_i: 7.992591 | si-snr: 7.800739288330078 | si-snr_i: 7.688427925109863\n",
      "status: Best | sdr: 15.501514 | sdr_i: 15.429669 | si-snr: 15.043062210083008 | si-snr_i: 15.05727481842041\n",
      "mean_values sdr         7.552595\n",
      "sdr_i       7.373364\n",
      "si-snr      6.919567\n",
      "si-snr_i    6.919053\n",
      "dtype: float64\n",
      "------------CONFIG: no_noise_speedperturb | upsampled: True\n",
      "status: Worst | sdr: -1.9536307 | sdr_i: -4.146778 | si-snr: -6.002154350280762 | si-snr_i: -6.214303493499756\n",
      "status: Median | sdr: 7.672893 | sdr_i: 7.491629 | si-snr: 6.4334564208984375 | si-snr_i: 6.3864946365356445\n",
      "status: Best | sdr: 13.262935 | sdr_i: 12.98933 | si-snr: 11.85539436340332 | si-snr_i: 11.82516098022461\n",
      "mean_values sdr         6.974600\n",
      "sdr_i       6.795369\n",
      "si-snr      5.608129\n",
      "si-snr_i    5.607615\n",
      "dtype: float64\n",
      "------------CONFIG: w_noise_speedperturb | upsampled: False\n",
      "status: Worst | sdr: -2.5979092 | sdr_i: -2.7904358 | si-snr: -4.536081314086914 | si-snr_i: -4.614652633666992\n",
      "status: Median | sdr: 12.310665 | sdr_i: 12.223931 | si-snr: 11.65188217163086 | si-snr_i: 11.757654190063477\n",
      "status: Best | sdr: 17.720842 | sdr_i: 17.707638 | si-snr: 17.363319396972656 | si-snr_i: 17.402938842773438\n",
      "mean_values sdr         11.661978\n",
      "sdr_i       11.482767\n",
      "si-snr      10.964631\n",
      "si-snr_i    10.964134\n",
      "dtype: float64\n",
      "------------CONFIG: w_noise_speedperturb | upsampled: True\n",
      "status: Worst | sdr: -2.9354887 | sdr_i: -3.1280153 | si-snr: -4.858060836791992 | si-snr_i: -4.93663215637207\n",
      "status: Median | sdr: 11.97229 | sdr_i: 11.846306 | si-snr: 10.480037689208984 | si-snr_i: 10.460012435913086\n",
      "status: Best | sdr: 15.773295 | sdr_i: 15.499692 | si-snr: 14.806492805480955 | si-snr_i: 14.776259422302246\n",
      "mean_values sdr         11.010887\n",
      "sdr_i       10.831676\n",
      "si-snr       9.830495\n",
      "si-snr_i     9.829999\n",
      "dtype: float64\n",
      "------------CONFIG: w_noise_wavedrop | upsampled: False\n",
      "status: Worst | sdr: -3.3337429 | sdr_i: -1.2669749 | si-snr: -4.311795711517334 | si-snr_i: -2.0954952239990234\n",
      "status: Median | sdr: 9.020053 | sdr_i: 12.223116 | si-snr: 8.419578552246094 | si-snr_i: 11.809675216674805\n",
      "status: Best | sdr: 15.202989 | sdr_i: 15.816387 | si-snr: 14.601505279541016 | si-snr_i: 15.272643089294434\n",
      "mean_values sdr          8.676393\n",
      "sdr_i       10.456626\n",
      "si-snr       7.901124\n",
      "si-snr_i     9.896094\n",
      "dtype: float64\n",
      "------------CONFIG: w_noise_wavedrop | upsampled: True\n",
      "status: Worst | sdr: -1.747132 | sdr_i: 1.6636828 | si-snr: -4.638113975524902 | si-snr_i: 0.5032539367675781\n",
      "status: Median | sdr: 8.658081 | sdr_i: 9.733515 | si-snr: 7.677304744720459 | si-snr_i: 8.865992546081543\n",
      "status: Best | sdr: 14.670143 | sdr_i: 15.283542 | si-snr: 12.865909576416016 | si-snr_i: 13.537047386169434\n",
      "mean_values sdr          8.301278\n",
      "sdr_i       10.081512\n",
      "si-snr       7.178982\n",
      "si-snr_i     9.173952\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import shutil\n",
    "# Get worst\n",
    "def get_worst(column,df):\n",
    "   return df.loc[df[column].idxmin()]\n",
    "# Get best \n",
    "def get_best(column,df):\n",
    "   return df.loc[df[column].idxmax()]\n",
    "# Get Median\n",
    "def get_median(column,df):\n",
    "   df.loc[df[column]== df[column].median()]\n",
    "   df.sort_values(by=column, inplace=True)\n",
    "   return df[df[column] < df[column].median()].iloc[-1]\n",
    "\n",
    "\n",
    "def print_audio_info(stat, df):\n",
    "   print(f\"status: {stat} | sdr: {df['sdr']} | sdr_i: {df['sdr_i']} | si-snr: {df['si-snr']} | si-snr_i: {df['si-snr_i']}\")\n",
    "\n",
    "def write_demo_audio(src_path,dest_path):\n",
    "   shutil.copy(src_path, dest_path)\n",
    "\n",
    "def write_image(dest_path):\n",
    "   pass\n",
    "   \n",
    "status = ['Worst', 'Median', 'Best']\n",
    "\n",
    "configs = [\"epoch_30\", \"no_noise_speedperturb\",\"w_noise_speedperturb\", \"w_noise_wavedrop\"]\n",
    "# configs = [\"no_noise_speedperturb\"]\n",
    "for config in configs:\n",
    "   for upsample in [False, True]:\n",
    "      df = pd.read_csv(f'results/{config}/{config}_{upsample}_test.csv')\n",
    "      df.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "   # drop rows with NaNs\n",
    "      df.dropna(inplace=True)\n",
    "      # df.replace()\n",
    "      print(f\"------------CONFIG: {config} | upsampled: {upsample}\")\n",
    "      worst = get_worst('si-snr',df)\n",
    "      median = get_median('si-snr',df)\n",
    "      best = get_best('si-snr',df)\n",
    "      print_audio_info(status[0], worst)\n",
    "      print_audio_info(status[1], median)\n",
    "      print_audio_info(status[2], best)\n",
    "\n",
    "      mean_values = df.loc[:, df.columns != 'snt_id'].mean()\n",
    "      print(f'mean_values {mean_values}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>snt_id</th>\n",
       "      <th>sdr</th>\n",
       "      <th>sdr_i</th>\n",
       "      <th>si-snr</th>\n",
       "      <th>si-snr_i</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>item0</td>\n",
       "      <td>8.709541</td>\n",
       "      <td>12.099934</td>\n",
       "      <td>7.763442</td>\n",
       "      <td>11.358368</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>item1</td>\n",
       "      <td>-1.304001</td>\n",
       "      <td>-0.404314</td>\n",
       "      <td>-2.374741</td>\n",
       "      <td>-1.409151</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>item10</td>\n",
       "      <td>10.374760</td>\n",
       "      <td>11.388518</td>\n",
       "      <td>9.455255</td>\n",
       "      <td>10.703505</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>item100</td>\n",
       "      <td>8.781614</td>\n",
       "      <td>10.849915</td>\n",
       "      <td>7.796484</td>\n",
       "      <td>10.323214</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>item1000</td>\n",
       "      <td>8.809902</td>\n",
       "      <td>9.547372</td>\n",
       "      <td>8.316668</td>\n",
       "      <td>9.167922</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     snt_id        sdr      sdr_i    si-snr   si-snr_i\n",
       "0     item0   8.709541  12.099934  7.763442  11.358368\n",
       "1     item1  -1.304001  -0.404314 -2.374741  -1.409151\n",
       "2    item10  10.374760  11.388518  9.455255  10.703505\n",
       "3   item100   8.781614  10.849915  7.796484  10.323214\n",
       "4  item1000   8.809902   9.547372  8.316668   9.167922"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df.sort_values(by='snt_id')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "# import librosa\n",
    "\n",
    "# # Load the original audio signal\n",
    "# audio_file_orig = 'original_audio.wav'\n",
    "# y_orig, sr_orig = librosa.load(audio_file_orig)\n",
    "\n",
    "# # Load the upsampled audio signal\n",
    "# audio_file_upsamp = 'upsampled_audio.wav'\n",
    "# y_upsamp, sr_upsamp = librosa.load(audio_file_upsamp)\n",
    "\n",
    "# # Compute the SNR of the upsampled audio signal compared to the original signal\n",
    "# diff = np.sum((y_orig - y_upsamp)**2)\n",
    "# snr = 10 * np.log10(np.sum(y_orig**2) / diff)\n",
    "\n",
    "# print('SNR: {:.2f} dB'.format(snr))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spectral centroid difference: -215.47\n",
      "Spectral rolloff difference: -267.58\n",
      "Spectral centroid std difference: -97.98\n",
      "Spectral rolloff std difference: -108.21\n"
     ]
    }
   ],
   "source": [
    "import librosa\n",
    "\n",
    "# Load the original audio signal\n",
    "audio_file_orig = 'original_audio.wav'\n",
    "y_orig, sr_orig = librosa.load(audio_file_orig)\n",
    "\n",
    "# Load the upsampled audio signal\n",
    "audio_file_upsamp = 'upsampled_audio.wav'\n",
    "y_upsamp, sr_upsamp = librosa.load(audio_file_upsamp)\n",
    "\n",
    "# Compute the spectral centroid and rolloff of the original and upsampled audio signals\n",
    "spec_centroid_orig = librosa.feature.spectral_centroid(y_orig, sr=sr_orig)[0]\n",
    "spec_rolloff_orig = librosa.feature.spectral_rolloff(y_orig, sr=sr_orig)[0]\n",
    "\n",
    "spec_centroid_upsamp = librosa.feature.spectral_centroid(y_upsamp, sr=sr_upsamp)[0]\n",
    "spec_rolloff_upsamp = librosa.feature.spectral_rolloff(y_upsamp, sr=sr_upsamp)[0]\n",
    "\n",
    "# Compute the mean and standard deviation of the spectral features\n",
    "centroid_diff = spec_centroid_orig.mean() - spec_centroid_upsamp.mean()\n",
    "rolloff_diff = spec_rolloff_orig.mean() - spec_rolloff_upsamp.mean()\n",
    "\n",
    "centroid_std_diff = spec_centroid_orig.std() - spec_centroid_upsamp.std()\n",
    "rolloff_std_diff = spec_rolloff_orig.std() - spec_rolloff_upsamp.std()\n",
    "\n",
    "# Print the results\n",
    "print('Spectral centroid difference: {:.2f}'.format(centroid_diff))\n",
    "print('Spectral rolloff difference: {:.2f}'.format(rolloff_diff))\n",
    "\n",
    "print('Spectral centroid std difference: {:.2f}'.format(centroid_std_diff))\n",
    "print('Spectral rolloff std difference: {:.2f}'.format(rolloff_std_diff))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(22050, 22050)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sr_upsamp, sr_orig"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "inference",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
